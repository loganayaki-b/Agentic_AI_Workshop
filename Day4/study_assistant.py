# -*- coding: utf-8 -*-
"""study assistant.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cH6AYcp1OUVPs0I5ezMxanw_3p-jriaF
"""

!pip install PyPDF2 langchain langchain-google-genai google-generativeai

import os
os.environ["GOOGLE_API_KEY"] = "AIzaSyDyISlBjQ_oYINPse2p-b7mZFSz8o0QhEw"  # Replace with your Gemini API key

import PyPDF2

def extract_text_from_pdf(pdf_path):
    with open(pdf_path, "rb") as file:
        reader = PyPDF2.PdfReader(file)
        text = ""
        for page in reader.pages:
            text += page.extract_text()
    return text

# Upload PDF
from google.colab import files
uploaded = files.upload()
pdf_path = list(uploaded.keys())[0]

# Extract content
study_material = extract_text_from_pdf(pdf_path)
print(study_material[:1000])  # Preview

from langchain_google_genai import ChatGoogleGenerativeAI

llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0.3)

from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

summary_prompt = PromptTemplate(
    input_variables=["text"],
    template="Summarize the following study material into concise bullet points:\n\n{text}"
)

summary_chain = LLMChain(llm=llm, prompt=summary_prompt)
summary = summary_chain.run(study_material)
print("Summary:\n", summary)

question_prompt = PromptTemplate(
    input_variables=["summary"],
    template="""
From the following summary, create 3 multiple-choice quiz questions.
Each question must include 4 options (a-d) and clearly state the correct answer.

Summary:
{summary}
"""
)

question_chain = LLMChain(llm=llm, prompt=question_prompt)
questions = question_chain.run(summary)
print("Quiz Questions:\n", questions)