# -*- coding: utf-8 -*-
"""Travel assistant.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G9zt8CiDjZOausz0Ggw0UfnedR7x7sGM
"""

!pip install langchain langchain-google-genai duckduckgo-search requests

import os

# Gemini API Key
os.environ["GOOGLE_API_KEY"] = "AIzaSyDyISlBjQ_oYINPse2p-b7mZFSz8o0QhEw"  # Replace with your actual Gemini key

# WeatherAPI Key
weather_api_key = "246be2fdf3cd4667b4664902251306"  # Replace with your key from https://www.weatherapi.com

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.agents import initialize_agent, AgentType, AgentExecutor, create_tool_calling_agent
from langchain.tools import Tool

import requests
from langchain.tools import tool

@tool
def get_weather(city: str) -> str:
    """Get current weather for a city"""
    url = f"http://api.weatherapi.com/v1/current.json?key={weather_api_key}&q={city}"
    response = requests.get(url)
    data = response.json()

    if "current" in data:
        temp_c = data['current']['temp_c']
        condition = data['current']['condition']['text']
        return f"The current weather in {city} is {temp_c}Â°C with {condition}."
    else:
        return "Weather information not available."

from duckduckgo_search import DDGS

@tool
def get_top_attractions(city: str) -> str:
    """Get top tourist attractions in a city"""
    query = f"Top tourist attractions in {city}"
    results = DDGS().text(query, max_results=5)
    places = [res['title'] for res in results]
    return "Top attractions:\n" + "\n".join(places)

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.agents import initialize_agent, AgentType, AgentExecutor, create_tool_calling_agent
from langchain.tools import Tool
from langchain_core.prompts import ChatPromptTemplate

# ... (previous code)

llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0.3)

tools = [get_weather, get_top_attractions]

# Define the prompt template
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful assistant that can get weather information and top attractions for a city."),
    ("human", "{input}"),
    ("placeholder", "{agent_scratchpad}"),
])

# Pass the prompt to create_tool_calling_agent
agent = create_tool_calling_agent(llm=llm, tools=tools, prompt=prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

# ... (rest of the code)

destination = input("Enter a destination city: ")
response = agent_executor.invoke({"input": destination})
print("\nðŸ§  AI Response:\n", response["output"])

# Let's assume `response["output"]` holds the AI's final answer
ai_output = response["output"]

# Define the file path
output_path = "/content/travel_assistant_output.txt"

# Write the AI response to the file
with open(output_path, "w", encoding="utf-8") as file:
    file.write("ðŸ§³ Travel Assistant Output\n")
    file.write("==========================\n\n")
    file.write(f"Destination: {destination}\n\n")
    file.write(ai_output)

# Download the file to your local system
from google.colab import files
files.download(output_path)